{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import binascii\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_divided_groups(sorted_dataframe: pd.DataFrame, file_num_list: list) -> list: # return with grouped groups as one list, and get their labels\n",
    "    filename_list = []\n",
    "    itr = 0\n",
    "    _filname_list = np.array(sorted_dataframe.loc[:, ('SrcAddr', 'Sport', 'DstAddr', 'Dport', 'StartTime')]).tolist()\n",
    "    for count in file_num_list:\n",
    "        _filelist = _filname_list[itr:itr + count]\n",
    "        filename_list.append(_filelist)\n",
    "        itr += count\n",
    "    return filename_list\n",
    "\n",
    "def generate_filelist_toread(dir_of_one_proto):\n",
    "    _filelist = os.listdir(dir_of_one_proto)\n",
    "#             filelist = []\n",
    "    ###### get a dataframe of all split filename for further processing\n",
    "    filelist = [os.path.splitext(filename)[0] for filename in _filelist]\n",
    "    split_filename = [filename.split('_', 4) for filename in filelist]\n",
    "    filename_df = pd.DataFrame(split_filename)\n",
    "    filename_df.rename(columns={0: 'SrcAddr', 1: 'Sport',\n",
    "                                2: 'DstAddr', 3: 'Dport',\n",
    "                                4:'StartTime'}, inplace=True)\n",
    "    \n",
    "    # temp GroupByObject of data grouped by ['SrcAddr', 'Sport', 'DstAddr', 'Dport']\n",
    "    divided_group_object = filename_df.groupby(['SrcAddr', 'Sport', 'DstAddr', 'Dport'], sort = False)\n",
    "\n",
    "    # sort data in each group by 'StartTime'\n",
    "    processed_dataflow = divided_group_object.apply(lambda x:x.sort_values('StartTime', ascending = True))                                                .reset_index(drop = True)\n",
    "#     processed_dataflow =  divided_group_object.apply(lambda x: x).reset_index(drop = True)\n",
    "\n",
    "    # data number in different groups, used to extract ordered groups from processed_dataflow\n",
    "    processed_group_num = np.array(divided_group_object['SrcAddr'].count()).tolist()\n",
    "    split_filenamelist_in_list = extract_divided_groups(processed_dataflow, processed_group_num)\n",
    "    \n",
    "    ###### pack all filenames with same ['SrcAddr', 'Sport', 'DstAddr', 'Dport'] in one list\n",
    "    ###### each list was sorted by 'StartTime' inside, and pack all filename lists in one list\n",
    "    filenamelist_in_list = []\n",
    "    for split_str_list in tqdm(split_filenamelist_in_list, desc='Progress'):\n",
    "        filename_list = [] # filename in one flow\n",
    "        for split_str in split_str_list:\n",
    "            filename = '_'.join(split_str)\n",
    "            filename_list.append(dir_of_one_proto + filename + '.pcap')\n",
    "        filenamelist_in_list.append(filename_list)\n",
    "    \n",
    "    return filenamelist_in_list\n",
    "\n",
    "\n",
    "def pcap2hex(filename) -> bytes :\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'rb') as reader:\n",
    "            reader.seek(24, 1) # jump over pcap head\n",
    "            binflow = reader.read()\n",
    "            hexstr = binascii.b2a_hex(binflow)\n",
    "    # no such file\n",
    "    else: return b'' # this is a bytes type string!!!!!!!\n",
    "    return hexstr\n",
    "\n",
    "def readfile_bylist(one_flow_file_list: list): # find pcap file by generated filename\n",
    "    picstr = b'' # bytes string to be written in picture\n",
    "    for filename in one_flow_file_list:\n",
    "        hexstr = pcap2hex(filename)\n",
    "        \n",
    "        if hexstr != b'' and len(picstr) < 2048: # picstr length is more than 1024B\n",
    "            picstr += hexstr\n",
    "        elif hexstr == b'' and len(picstr) < 2048:\n",
    "            continue # no such file matches with generated filename\n",
    "        else: break\n",
    "            \n",
    "    # picstr length >= 2048\n",
    "    if len(picstr) >= 2048:\n",
    "        picstr = picstr[:2048]\n",
    "    else:\n",
    "        picstr = picstr.ljust(2048, b'0')\n",
    "        \n",
    "    return picstr\n",
    "\n",
    "def hex2pic(picstr):\n",
    "    pic_array = np.array([int(picstr[i:i+2], 16) for i in range(0, 2048, 2)]).reshape(32, 32)\n",
    "#     img = Image.fromarray(np.uint8(pic_array))\n",
    "    return pic_array\n",
    "\n",
    "'''\n",
    "NOTICE:\n",
    "Actually, packets from or to '172.16.2.11' and '172.16.2.12' contains EITHER malicious data OR NON-malicious data,\n",
    "but I can't really tell their difference for the way I process 'ISOT_Botnet_DataSet_2010.pcap' file into separate pcap files (with pkt2flow)\n",
    "droped some details during its process. Take the file name as an instance, ports marked in hex code(0x12) will be renamed only as a singel '0':\n",
    "\n",
    "e.g: 10.0.0.254_**0x12**_172.16.0.11_**0x56**_1286402882 -> 10.0.0.254_**0**_172.16.0.11_**0**_1286402882 after processing\n",
    "\n",
    "As you see, flows with this hex code, like flows using ICMP protocol, can't be classified by its name,\n",
    "so I just simply dropped these data, and only flows using TCP/UDP protocol are used.\n",
    "\n",
    "Preprocessing on IP addresses here is alike, because flows using MAC address 'CC:CC:CC:DD:DD:DD' are all dismissed,\n",
    "flows with uncertain IP addresses are marked as 'botnet' to avoid bad influences (and we actually have enough data to train the model).\n",
    "Oh, and yes, we only use 'normal' data so all uncertainty will be eliminated :D.\n",
    "'''\n",
    "\n",
    "def get_isot_label_bypath(file_path):\n",
    "    if '172.16.0.2' in file_path or '172.16.0.11' in file_path or '172.16.0.12' in file_path         or '172.16.2.11' in file_path or '172.16.2.12' in file_path or 'ff' in file_path:\n",
    "        return 'botnet'\n",
    "    else:\n",
    "        return 'normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: /root/ISOT-2010/isot/udp/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df029e8371aa47bd84ea1f63ec69fb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Progress', max=530253.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing directory: /root/ISOT-2010/isot/tcp_nosyn/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0239c69266d4e3599e28da0a53f9ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Progress', max=31122.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing directory: /root/ISOT-2010/isot/tcp_syn/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753b4b555c8c426aa9675d97f2a621a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Progress', max=489214.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dirpath = '/mnt/e/1IDM/CTU-13-Backup/'\n",
    "dirpath = '/root/ISOT-2010/isot/'\n",
    "        \n",
    "# dataset_list = ['CTU-13.Dataset-42', 'CTU-13.Dataset-43', 'CTU-13.Dataset-44', \n",
    "#                     'CTU-13.Dataset-45', 'CTU-13.Dataset-46', 'CTU-13.Dataset-47', \n",
    "#                     'CTU-13.Dataset-48', 'CTU-13.Dataset-49', 'CTU-13.Dataset-50',\n",
    "#                     'CTU-13.Dataset-51', 'CTU-13.Dataset-52', 'CTU-13.Dataset-53'] # 'CTU-13.Dataset-51' is skipped\n",
    "# proto_list = ['/botnet/udp/', '/botnet/tcp_nosyn/', '/botnet/tcp_syn/'] # skip 'icmp' or other protos\n",
    "proto_list = ['udp/', 'tcp_nosyn/', 'tcp_syn/'] # skip 'icmp' or other protos\n",
    "\n",
    "all_filename_lists = []\n",
    "        \n",
    "for proto in proto_list:\n",
    "    if os.path.exists(dirpath + proto):\n",
    "        print('Processing directory: ' + dirpath + proto)\n",
    "        filename_toread = generate_filelist_toread(dirpath + proto)\n",
    "        \n",
    "#         if get_isot_label_bypath(filename_toread[0][0])\n",
    "        all_filename_lists.extend(filename_toread)\n",
    "#         print('Processed directory: ' + dirpath + proto)\n",
    "    else: print('no such directory: ' + dirpath + proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c215ffb9d8a8446684341f7ceb234c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting ISOT-2010 pcap to images', max=1050589.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# imagelist = []\n",
    "labellist = []\n",
    "# image_path = '/mnt/e/1IDM/CTU-13-Backup/grayscale/'\n",
    "# image_path = '/root/ISOT-2010/isot/trial/'\n",
    "image_path = '/root/ISOT-2010/isot/grayscale/'\n",
    "if os.path.exists(image_path) == False:\n",
    "    os.mkdir(image_path)\n",
    "        \n",
    "image_num = len(all_filename_lists)\n",
    "skip_flag = 0\n",
    "\n",
    "for filename_list in tqdm(all_filename_lists, desc='Converting ISOT-2010 pcap to images'):\n",
    "    # skip this file list if it's all about 'botnet'\n",
    "    if get_isot_label_bypath(filename_list[0]) == 'botnet':\n",
    "        skip_flag += 1\n",
    "        continue   \n",
    "    # skip this file list if there's a file with the same name\n",
    "    im_name = os.path.splitext(os.path.basename(filename_list[0]))[0]\n",
    "    file_name = image_path + im_name + '.bmp'\n",
    "    if os.path.exists(file_name) == True:\n",
    "        skip_flag += 1\n",
    "        continue\n",
    "    \n",
    "    # process pcap into picture if not 'botnet'\n",
    "    picture_str = readfile_bylist(filename_list)\n",
    "    im = hex2pic(picture_str)\n",
    "#     imagelist.append(im)\n",
    "#     im_name = os.path.splitext(os.path.basename(filename_list[0]))[0]\n",
    "#         im.save(image_path + im_name + '.bmp')\n",
    "    cv2.imwrite(file_name, im)\n",
    "    label = get_isot_label_bypath(filename_list[0])\n",
    "    labellist.append([im_name, label])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1050589 images at 2020-04-09 13:09:45.491153\n",
      "Skipped 63881 botnet images\n"
     ]
    }
   ],
   "source": [
    " \n",
    "#         if cnt % 10000 == 0:\n",
    "#             print('Processed %s pictures' % cnt)\n",
    "#             print(datetime.datetime.now())\n",
    "    #     if picture_str != b''.ljust(2048, b'0'):\n",
    "    #         im = hex2pic(picture_str)\n",
    "    #         imagelist.append(im)\n",
    "    #         labellist.append(all_data_label[i])\n",
    "\n",
    "assert len(os.listdir(image_path)) == len(labellist)\n",
    "print('Processed {0} images at {1}'.format(image_num, datetime.datetime.now()))\n",
    "print('Skipped {0} botnet images'.format(skip_flag))\n",
    "\n",
    "label_df = pd.DataFrame(labellist, columns = ['PicName', 'Label'])\n",
    "# label_df.to_csv('/mnt/e/1IDM/CTU-13-Backup/label.csv', encoding = 'utf-8')\n",
    "label_df.to_csv('/root/ISOT-2010/isot/isot.csv', index = 0, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9fa2c7286448c98c715736d3f87d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='test', max=1200.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(1200), desc='test'):\n",
    "#     time.sleep(0.01)\n",
    "    continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
